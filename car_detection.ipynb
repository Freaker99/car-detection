{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1qT0ljzGAMB0inCouexfN8NKoE5T3CTJ_",
      "authorship_tag": "ABX9TyOTOEGYp4cuaOSn68QI5wVD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Freaker99/car-detection/blob/main/car_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "Mount drive with data."
      ],
      "metadata": {
        "id": "rQwFkaDIZe1_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WvVYIGxYMnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0510b547-ffe1-422c-bd7f-f63a229a273c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')\n",
        "root = '/content/drive/My Drive/car-detection/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install YOLOv5 package."
      ],
      "metadata": {
        "id": "UKtVzhZLkrv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yolov5"
      ],
      "metadata": {
        "id": "0yIDThdVruEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install libriaries, clone GitHub repository, YOLOv5's weeights, install requirements."
      ],
      "metadata": {
        "id": "5B6kx603mfas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install opencv-python\n",
        "#!pip install torch torchvision\n",
        "#!pip install numpy\n",
        "#!pip install ultralytics\n",
        "\n",
        "#!git clone https://github.com/ultralytics/yolov5\n",
        "#!wget https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt\n",
        "#%cd yolov5\n",
        "#!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "okzOlMLANDFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all dependencies."
      ],
      "metadata": {
        "id": "682CZj19lVqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import shutil\n",
        "import subprocess\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.transforms.functional import resize\n",
        "from torchvision.models import resnet50\n",
        "from torch.utils.data import DataLoader\n",
        "from yolov5.models.yolo import Model\n",
        "from numpy import True\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "GLkW4yralXLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BDD100KDataset"
      ],
      "metadata": {
        "id": "S5PaGXrLZqjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BDD100KDataset(VisionDataset):\n",
        "    def __init__(self, labels_file, image_dir, transform=None, target_transform=None, resize_size=(256, 256), crop_size=(224, 224)):\n",
        "        super(BDD100KDataset, self).__init__(image_dir, transform=transform, target_transform=target_transform)\n",
        "        self.labels = self._read_labels(labels_file)\n",
        "        self.images = [item[\"name\"] for item in self.labels]\n",
        "        self.resize_size = resize_size\n",
        "        self.crop_size = crop_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = os.path.join(self.root, self.images[index])\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image = transforms.Resize(self.resize_size)(image)  #\n",
        "        image = transforms.RandomCrop(self.crop_size)(image)  # Przekształcenie losowego wycięcia\n",
        "        label = self.labels[index]\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform is not None:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def _read_labels(self, labels_file):\n",
        "        with open(labels_file, \"r\") as f:\n",
        "            labels = json.load(f)\n",
        "        return labels"
      ],
      "metadata": {
        "id": "SS18orYgUGiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rezising images to the same resolution."
      ],
      "metadata": {
        "id": "SbcT1tBLmLbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(image, target):\n",
        "    image = image.resize((224, 224))\n",
        "    image = torch.Tensor(np.array(image)).permute(2, 0, 1) / 255.0  # Konwersja na tensor i normalizacja\n",
        "    target = torch.Tensor(target)\n",
        "    return image, target"
      ],
      "metadata": {
        "id": "wrJvgHA5Ih1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ścieżki do folderów z obrazami\n",
        "image_dir_train = '/content/drive/My Drive/car-detection/images/train/train100k'\n",
        "image_dir_val = '/content/drive/My Drive/car-detection/images/val/'\n",
        "\n",
        "# Ścieżki do plików etykiet\n",
        "train_labels_file = '/content/drive/My Drive/car-detection/labels/det_train.json'\n",
        "val_labels_file = '/content/drive/My Drive/car-detection/labels/det_val.json'\n",
        "\n",
        "# Tworzenie instancji datasetu treningowego i walidacyjnego\n",
        "train_dataset = BDD100KDataset(train_labels_file, image_dir_train, transform=transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "val_dataset = BDD100KDataset(val_labels_file, image_dir_val, transform=transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "# Definiowanie DataLoader dla treningu i walidacji\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0, drop_last=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "q8YtjtlgLDf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "mQ_wQgHPneUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pin_memory = True\n",
        "\n",
        "# Funkcja treningowa\n",
        "def train(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for images, labels in tqdm(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "2rDLMBKNne4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicjalizacja modelu YOLOv5\n",
        "model = Model(root + \"yolov5/models/yolov5s.yaml\")\n",
        "\n",
        "# Załadowanie wstępnie wytrenowanych wag modelu\n",
        "state_dict = torch.load(root + \"yolov5/yolov5s.pt\")\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Ustawienie trybu trenowania modelu\n",
        "model.train()\n",
        "\n",
        "# Definicja optymalizatora\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Definicja funkcji straty\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Parametry trenowania\n",
        "num_epochs = 10\n",
        "batch_size = 2\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "\n",
        "# Pętla trenowania\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    # Trening\n",
        "    train_loss = train(model, train_loader, criterion, optimizer)\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Ocena na zbiorze walidacyjnym (opcjonalnie)\n",
        "    # val_loss = evaluate(model, val_loader, criterion)\n",
        "    # print(f\"Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "# Zapisanie wytrenowanego modelu\n",
        "torch.save(model.state_dict(), \"trained_model.pt\")"
      ],
      "metadata": {
        "id": "J8V_ZSg1lS87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools"
      ],
      "metadata": {
        "id": "1UsYp3abtjK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_large_file(input_file, output_folder):\n",
        "    with open(input_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    for label in data:\n",
        "        name = label['name'].replace('.jpg', '.txt')\n",
        "        output_path = os.path.join(output_folder, name)\n",
        "\n",
        "        with open(output_path, 'w') as txt_file:\n",
        "            json.dump(label, txt_file)\n",
        "\n",
        "        print(f\"Zapisano plik: {name}\")\n",
        "\n",
        "# Wprowadź ścieżkę do swojego dużego pliku tekstowego\n",
        "#input_file = '/content/drive/My Drive/car-detection/labels/det_val_txt.txt'\n",
        "input_file = '/content/drive/My Drive/car-detection/labels/det_train_txt.txt'\n",
        "\n",
        "# Określ folder, w którym będą zapisywane podzielone pliki\n",
        "#output_folder = '/content/drive/My Drive/car-detection/labels/labels_val_txt'\n",
        "output_folder = '/content/drive/My Drive/car-detection/labels/labels_train_txt'\n",
        "\n",
        "# Wywołaj funkcję do podziału pliku\n",
        "split_large_file(input_file, output_folder)"
      ],
      "metadata": {
        "id": "T_eTC-ritjW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_yolov5(input_folder, output_folder):\n",
        "    # Słownik mapujący klasy na indeksy w formacie YOLOv5\n",
        "    class_mapping = {\n",
        "        \"pedestrian\": 0,\n",
        "        \"bicycle\": 1,\n",
        "        \"car\": 2,\n",
        "        \"motorcycle\": 3,\n",
        "        \"bus\": 5,\n",
        "        \"train\": 6,\n",
        "        \"truck\": 7,\n",
        "        \"traffic light\": 9,\n",
        "        \"traffic sign\": 11\n",
        "        # Brak klasy \"rider\", bo jest nieistotna\n",
        "    }\n",
        "\n",
        "    # Sprawdź istnienie folderu wyjściowego; jeśli nie istnieje, utwórz go\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    count = 0\n",
        "   # Przetwarzaj każdy plik w folderze wejściowym\n",
        "    for filename in os.listdir(input_folder):\n",
        "        input_file = os.path.join(input_folder, filename)\n",
        "        output_file = os.path.join(output_folder, filename)\n",
        "\n",
        "        with open(input_file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            print(\"teraz przetwarzam\" + str(count) + input_file)\n",
        "\n",
        "        # Sprawdź, czy klucz 'labels' istnieje w danych\n",
        "        if 'labels' in data:\n",
        "            with open(output_file, 'w') as f:\n",
        "                for label in data['labels']:\n",
        "                    category = label.get('category', '')\n",
        "                    if category in class_mapping:\n",
        "                        class_index = class_mapping[category]\n",
        "\n",
        "                        x1 = label['box2d'].get('x1', 0)\n",
        "                        y1 = label['box2d'].get('y1', 0)\n",
        "                        x2 = label['box2d'].get('x2', 0)\n",
        "                        y2 = label['box2d'].get('y2', 0)\n",
        "\n",
        "                        # Oblicz współrzędne środka oraz szerokość i wysokość bounding boxa\n",
        "                        width = x2 - x1\n",
        "                        height = y2 - y1\n",
        "                        x_center = x1 + width / 2\n",
        "                        y_center = y1 + height / 2\n",
        "\n",
        "                        # Przeskaluj współrzędne do zakresu 0-1\n",
        "                        x_center /= 1280\n",
        "                        y_center /= 720\n",
        "                        width /= 1280\n",
        "                        height /= 720\n",
        "\n",
        "                        # Zapisz wynikowy wiersz w formacie YOLOv5\n",
        "                        f.write(f\"{class_index} {x_center} {y_center} {width} {height}\\n\")\n",
        "        else:\n",
        "            print(f\"Brak klucza 'labels' w pliku: {filename}\")\n",
        "\n",
        "        print(f\"Przetworzono plik: {filename}\")\n",
        "        count = count +1\n",
        "\n",
        "# Wprowadź ścieżki do swojego folderu wejściowego i docelowego folderu YOLOv5\n",
        "#input_folder = \"/content/drive/My Drive/car-detection/labels/labels_val_txt\"\n",
        "input_folder = \"/content/drive/My Drive/car-detection/labels/labels_train_txt\"\n",
        "\n",
        "#output_folder = \"/content/drive/My Drive/car-detection/labels/labels_val_txt_yolov5\"\n",
        "output_folder = \"/content/drive/My Drive/car-detection/labels/labels_train_txt_yolov5\"\n",
        "\n",
        "convert_to_yolov5(input_folder, output_folder)"
      ],
      "metadata": {
        "id": "4b9J8xRMZlJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/My Drive/car-detection/labels/det_val.json\"\n",
        "output_folder = \"/content/drive/My Drive/car-detection/labels/labels_val_txt\"\n",
        "\n",
        "json_file = \"/content/drive/My Drive/car-detection/labels/det_val.json\"\n",
        "\n",
        "def create_txt_files(json_file, output_folder):\n",
        "    with open(json_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for item in data:\n",
        "        if 'name' in item and 'regions' in item:\n",
        "            file_name = item['name'].replace('.jpg', '.txt')\n",
        "            file_path = os.path.join(output_folder, file_name)\n",
        "            with open(file_path, 'w') as txt_file:\n",
        "                for region in item['regions']:\n",
        "                    for line in region.get('lines', []):\n",
        "                        txt_file.write(line + '\\n')\n",
        "    create_txt_files(file_path, output_folder)"
      ],
      "metadata": {
        "id": "w3Q0wykYPRG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check resolution\n",
        "\n",
        "def check_resolution(image_folder):\n",
        "    resolutions = set()\n",
        "\n",
        "    for filename in os.listdir(image_folder):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            filepath = os.path.join(image_folder, filename)\n",
        "            with Image.open(filepath) as img:\n",
        "                resolutions.add(img.size)\n",
        "\n",
        "    if len(resolutions) == 1:\n",
        "        print(\"Wszystkie obrazy mają tę samą rozdzielczość:\", resolutions.pop())\n",
        "    else:\n",
        "        print(\"Obrazy mają różne rozdzielczości:\", resolutions)\n",
        "\n",
        "image_folder_path = '/content/drive/My Drive/car-detection/images/val'\n",
        "check_resolution(image_folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsUGC91FJsY1",
        "outputId": "de04d945-9aa8-4eee-b6bc-b90937e8f933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wszystkie obrazy mają tę samą rozdzielczość: (1280, 720)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show inside of the file\n",
        "\n",
        "#file_path = \"/content/drive/My Drive/car-detection/labels/labels_val_txt/c79e169f-054f74e7.txt\"\n",
        "#file_path = \"/content/drive/My Drive/car-detection/labels/labels_val_txt/b1c66a42-6f7d68ca.txt\"\n",
        "file_path = \"/content/drive/My Drive/car-detection/labels/labels_train_txt/11ecaf4a-837e3550.txt\"\n",
        "with open(file_path, 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFqVf5S-JWOZ",
        "outputId": "0faac6fa-ba01-45fd-9b0a-008460fd66d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"name\": \"11ecaf4a-837e3550.jpg\", \"attributes\": {\"weather\": \"clear\", \"timeofday\": \"night\", \"scene\": \"highway\"}, \"timestamp\": 10000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Json syntax check\n",
        "\n",
        "def check_json_syntax(folder_path):\n",
        "    file_names = os.listdir(folder_path)\n",
        "\n",
        "    for file_name in file_names:\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        with open(file_path, 'r') as f:\n",
        "            try:\n",
        "                json.load(f)\n",
        "                print(f\"Plik {file_name} ma poprawną składnię JSON.\")\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Błąd składni JSON w pliku {file_name}: {e}\")\n",
        "\n",
        "# Wprowadź ścieżkę do folderu zawierającego pliki tekstowe\n",
        "#folder_path = \"/content/drive/My Drive/car-detection/labels/labels_val_txt\"\n",
        "folder_path = \"/content/drive/My Drive/car-detection/labels/labels_train_txt\"\n",
        "\n",
        "# Wywołaj funkcję sprawdzającą składnię JSON\n",
        "check_json_syntax(folder_path)"
      ],
      "metadata": {
        "id": "hVTbMTbQKioE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# File exists\n",
        "\n",
        "os.path.exists('/content/drive/My Drive/car-detection/images/train/train100k/8ec22bdd-58cd1abf.jpg')"
      ],
      "metadata": {
        "id": "ZWyM3sCWDQbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove files\n",
        "\n",
        "def remove_files(folder):\n",
        "    file_list = os.listdir(folder)\n",
        "    for file_name in file_list:\n",
        "        file_path = os.path.join(folder, file_name)\n",
        "        os.remove(file_path)\n",
        "        print(f\"Usunięto plik: {file_name}\")\n",
        "\n",
        "# Wprowadź ścieżkę do folderu\n",
        "folder = '/content/drive/My Drive/car-detection/labels/labels_val_txt'\n",
        "\n",
        "# Wywołaj funkcję do usuwania plików\n",
        "remove_files(folder)"
      ],
      "metadata": {
        "id": "OyIucE3cItp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print labels\n",
        "\n",
        "image_dir = \"/content/drive/My Drive/car-detection/images/train/\"\n",
        "labels_file = \"/content/drive/My Drive/car-detection/labels/bdd100k_labels_images_train.json\"  # Ścieżka do pliku z etykietami (dostosuj do swojej struktury danych)\n",
        "\n",
        "# Wczytanie danych etykiet\n",
        "with open(labels_file, \"r\") as f:\n",
        "    labels = json.load(f)\n",
        "\n",
        "# Sprawdzenie informacji o nazwach plików w etykietach\n",
        "for item in labels:\n",
        "    file_name = item[\"name\"]\n",
        "    # Tutaj możesz wydrukować nazwy plików lub wykonać inne operacje na danych etykiet\n",
        "\n",
        "# Porównanie nazw plików obrazów z informacjami w etykietach\n",
        "file_list = os.listdir(image_dir)\n",
        "for file_name in file_list:\n",
        "    if file_name not in [item[\"name\"] for item in labels]:\n",
        "        print(\"Brak informacji w etykietach dla pliku:\", file_name)"
      ],
      "metadata": {
        "id": "UgG_irnSYz7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print files\n",
        "\n",
        "image_dir = \"/content/drive/My Drive/car-detection/labels/labels_train_txt\"\n",
        "\n",
        "# Wyświetlenie listy plików w folderze\n",
        "file_list = os.listdir(image_dir)\n",
        "for file_name in file_list:\n",
        "    print(file_name)"
      ],
      "metadata": {
        "id": "e2q7cidzsRPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count files\n",
        "\n",
        "#!ls '/content/drive/My Drive/car-detection/labels/labels_train_txt' | wc -l\n",
        "!ls '/content/drive/My Drive/car-detection/labels/labels_train_txt_yolov5' | wc -l\n",
        "#!ls '/content/drive/My Drive/car-detection/images/train/train100k' | wc -l"
      ],
      "metadata": {
        "id": "SXxYvElTIv9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move files\n",
        "\n",
        "src_folder = '/content/drive/My Drive/car-detection'\n",
        "\n",
        "dst_folder = '/content/drive/My Drive/car-detection'\n",
        "\n",
        "file_list = glob.glob(os.path.join(src_folder, '*.jpg'))\n",
        "batch_size = 100  # Liczba plików w jednej partycji\n",
        "num_batches = len(file_list) // batch_size + 1\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    batch_files = file_list[start_idx:end_idx]\n",
        "\n",
        "    for file_path in batch_files:\n",
        "        file_name = os.path.basename(file_path)\n",
        "        dst_path = os.path.join(dst_folder, file_name)\n",
        "        shutil.move(file_path, dst_path)\n",
        "        print(f\"Przeniesiono plik: {file_name}\")"
      ],
      "metadata": {
        "id": "8wPtMOJXwreG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(json_data[0])"
      ],
      "metadata": {
        "id": "w0t_We8KlYl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_sciezek = set([element[\"name\"] for element in json_data])"
      ],
      "metadata": {
        "id": "lTPQ7W-UJ1OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dalsze prace"
      ],
      "metadata": {
        "id": "7p15s__0Zcsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO\n",
        "\n",
        "1.\n",
        "Przygotowanie danych do treningu\n",
        "Format json -> yaml\n",
        "**DONE**\n",
        "\n",
        "2.\n",
        "Przejście przez cały tutorial\n",
        "https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\n",
        "https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/#train-on-custom-data\n",
        "\n",
        "\n",
        "3.\n",
        "Plan eksperymentów:\n",
        "?\n",
        "\n",
        "4.\n",
        "Ewaluacja pretrenowanego modelu własnych danych BDD100K dataset (próba wyznaczenia prędkości)\n",
        "Ramka, wyrzucenie szumów (skoki prawo, lewo) regresja liniowa\n",
        "\n",
        "5.\n",
        "Wykorzystanie pre-trenowanego modelu na bazie coco128.yaml\n",
        "Dotrenowanie modelu na ograniczonej ilości klas zgodnie z labelami w coco128.yaml\n",
        "\n",
        "6.\n",
        "Wytrenowanie modelu od 0 na BDD100K DATASET (krok opcjonalny)\n",
        "\n",
        "\n",
        "## TODO_2\n",
        "\n",
        "1. DOCS postęp pracy\n",
        "\n",
        "2. Na czym był trenowany yolov5s.pt i ten w tutorialu?\n"
      ],
      "metadata": {
        "id": "qKxV4sD6Z8nM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mam obrazek o pewnej rozdzielczości i prostokąt opisany współrzędnymi. Chcę narysować ramkę, czego użyć?"
      ],
      "metadata": {
        "id": "9WT9-rHbkevG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mam pre-trenowany model, który rozpoznaje różne klasy obiektów. Zwraca ramkę, ma klasę samochód, mogę zacząc eksperymenty z wyznaczaniem prędkości, a jednocześnie dotrenowywać model z moimi danymi"
      ],
      "metadata": {
        "id": "eqceFGMEdADT"
      }
    }
  ]
}